{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6cbee2-90f7-4dcb-8edf-599e43c4c36c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We have previously discussed sentiment classification, which is the task of automatically determining the sentiment expressed in a piece of text. Sentiment classification plays an important role in natural language processing and has numerous practical applications in fields such as social media analysis, customer feedback analysis, and market sentiment prediction. Previously, you have implemented a sentiment classifier using Naive Bayes, a Feed Forward Neural Network, and an RNN-based model. However, in this assignment, you will be evaluating a Transformers-based sentiment classifier provided by Hugging Face, utilizing their pipeline feature. This assessment will be conducted on the IMDB movie reviews dataset.\n",
    "\n",
    "The IMDB dataset, a popular benchmark dataset in sentiment analysis, consists of a collection of movie reviews labeled with their corresponding sentiment (positive or negative). Each review is preprocessed and represented as a sequence of words, with the task being to predict the sentiment polarity based on this textual input.\n",
    "\n",
    "Transformer models, as accessed through Hugging Face's `pipeline('text-classification')`, are exceptionally well-suited for text classification tasks, including sentiment analysis. Unlike Long Short-Term Memory networks (LSTMs), Transformers leverage self-attention mechanisms. This architecture allows them to process entire sequences of text simultaneously, which is highly advantageous for understanding context and dependencies in textual data.\n",
    "\n",
    "By the end of this assignment, you will have gained valuable insights into the use of Hugging Face for sentiment classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d74c5d0-deb0-4647-8c16-fba4a22d753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36241fc3-0355-4f2b-8366-32acca8bf6fa",
   "metadata": {},
   "source": [
    "# Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286eb535-66a6-4f44-b17a-787f3ead3d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 7.81k/7.81k [00:00<00:00, 11.5MB/s]\n",
      "Downloading data: 100%|██████████| 21.0M/21.0M [00:02<00:00, 8.92MB/s]\n",
      "Downloading data: 100%|██████████| 20.5M/20.5M [00:02<00:00, 9.48MB/s]\n",
      "Downloading data: 100%|██████████| 42.0M/42.0M [00:04<00:00, 10.4MB/s]\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 174472.46 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 209159.25 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 217959.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "imdb = load_dataset(\"imdb\")\n",
    "# We will use only the first 1024 instances of the testset as using more data will reduce the inference speed drastically\n",
    "x_test = [instance['text'] for instance in imdb[\"test\"]]\n",
    "y_test = [instance['label'] for instance in imdb[\"test\"]]\n",
    "\n",
    "_, x_test, _, y_test = train_test_split(\n",
    "    x_test,  # Features\n",
    "    y_test,  # Labels\n",
    "    test_size=0.05,  # 5% for testing\n",
    "    random_state=42,  # For reproducibility\n",
    "    stratify=y_test       # Stratify split based on the labels to maintain balance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd08aa3-30f6-4cd4-94ce-8538407dd171",
   "metadata": {},
   "source": [
    "# Loading the model\n",
    "\n",
    "## <span style=\"color:red\"><b>Task 1</b></span>\n",
    "Load the `pipeline('text-classification')` to ceate a classifier, and then use it to predict sentiments on the testset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9037e455-8170-4d6a-93ab-2e2a472fa861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "2024-06-12 17:41:39.267981: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-06-12 17:41:39.268015: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-06-12 17:41:39.268028: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-06-12 17:41:39.268050: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-12 17:41:39.268063: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "classifier = pipeline('text-classification')\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc103e6d-1f2b-465e-b508-f1f68cbe2cee",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## <span style=\"color:red\"><b>Task 2</b></span>\n",
    "\n",
    "Calculate precision, recall, f1-score, and accuracy.\n",
    "How is the performance obrained compared to the previous sentiment classifiers you may have build in this unit?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d0e621-1552-4ab7-84b1-a62123703c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1250 [00:00<04:02,  5.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1250/1250 [05:00<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8880\n",
      "Precision: 0.9217\n",
      "Recall: 0.8480\n",
      "F1 Score: 0.8833\n",
      "Confusion Matrix:\n",
      "[[580  45]\n",
      " [ 95 530]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "predictions = []\n",
    "for text in tqdm(x_test):\n",
    "    result = classifier(text)[0]\n",
    "    predictions.append(1 if result['label'] == 'POSITIVE' else 0)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6716f54",
   "metadata": {},
   "source": [
    "### Hugging Face pipeline('text-classification'):\n",
    "- **Accuracy**: 0.8880\n",
    "- **Precision**: 0.9217\n",
    "- **Recall**: 0.8480\n",
    "- **F1-score**: 0.8833\n",
    "\n",
    "### RNN:\n",
    "- **Accuracy**: 0.8658\n",
    "- **Precision**: 0.8423\n",
    "- **Recall**: 0.9000\n",
    "- **F1-score**: 0.8702\n",
    "\n",
    "### Comparison:\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - Hugging Face: 0.8880\n",
    "   - RNN: 0.8658\n",
    "   - The Hugging Face pipeline achieves higher accuracy compared to the RNN model.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Hugging Face: 0.9217\n",
    "   - RNN: 0.8423\n",
    "   - The Hugging Face pipeline has significantly higher precision, indicating fewer false positives compared to the RNN model.\n",
    "\n",
    "3. **Recall**:\n",
    "   - Hugging Face: 0.8480\n",
    "   - RNN: 0.9000\n",
    "   - The RNN model achieves higher recall, indicating it correctly identifies more positive instances compared to the Hugging Face pipeline.\n",
    "\n",
    "4. **F1-score**:\n",
    "   - Hugging Face: 0.8833\n",
    "   - RNN: 0.8702\n",
    "   - The Hugging Face pipeline slightly outperforms the RNN model in terms of the F1-score, showing a better balance between precision and recall.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The Hugging Face pipeline('text-classification') outperforms the RNN model in terms of accuracy, precision, and F1-score. However, the RNN model has a higher recall. The higher precision and F1-score of the Hugging Face model suggest that it makes fewer false positive errors and has a better balance between precision and recall. The Hugging Face pipeline leverages powerful pre-trained Transformer models, which can capture contextual dependencies more effectively than the RNN, leading to better overall performance in sentiment classification tasks on the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a48bd-d5a0-4f9d-84e0-d167de691ded",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "\n",
    "Congratulations on completing the assignment! Your dedication and effort are commendable. By successfully working through this coding exercise, you should have gained valuable insights into the application of RNN-based neural networks for sentiment classification tasks and acquired practical skills in designing, training, and evaluating deep learning models on real-world datasets.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Acknowledgement\n",
    "\n",
    "## About the Author\n",
    "\n",
    "This notebook was authored by Mohamed Reda Bouadjenek. He is a Senior Lecturer (Assistant Professor) of Applied Artificial Intelligence in the School of Information Technology at Deakin University, Australia.\n",
    "\n",
    "\n",
    "\n",
    "## Disclaimer \n",
    "\n",
    "Even though your code passes all unit test cases, it does not guarantee absolute correctness. The complexity of real-world scenarios can sometimes lead to unforeseen edge cases that may not have been covered by the test suite. As a result, it's essential to exercise caution and conduct thorough testing to ensure the robustness and reliability of the code in all possible cases.\n",
    "\n",
    "## Version History\n",
    "- Version 1.0 (Initial Release): Released on 06/05/2024.\n",
    "\n",
    "## Contact Information\n",
    "\n",
    "- **Email:** reda.bouadjenek@deakin.edu.au\n",
    "- **GitHub:** https://github.com/rbouadjenek/\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
